{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "CHUNK_SIZE = 40960\n",
    "DATA_SOURCE_MAPPING = 'ucf-crime-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1710176%2F2799594%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240510%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240510T133953Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D154c1300ae6bb427e3431830121ae920ac33e472fdcd394da07081acd36d2a736e7d990a00f9e8024812c35419248d6f2ff3d94dbeedfe1bc3562f5ada2d119387fbbc7486707104329c184055eb6953772a0de0f1bf3c4eb6abb4c995993fded148dd22d42bde830375e0df13c709e32e382922bb18be93c571bda91d3504d97defcf1a003a7784825c8aa0aaa5ff53701af3276c7514ecb824fcc92e36577e3f5387d394de4fd2860bef1f317e28569f48c66b6d578f1427f7387c56dc645696394214d83957b117c2775b3a2be4c0d2f2cb9e734a5dc9517f66e2f1bde14862b1e9b5d393f9e42651a0dd253e87c7aadac7932b3714dfa3bf53ddd6d306d5'\n",
    "\n",
    "KAGGLE_INPUT_PATH='/kaggle/input'\n",
    "KAGGLE_WORKING_PATH='/kaggle/working'\n",
    "KAGGLE_SYMLINK='kaggle'\n",
    "\n",
    "!umount /kaggle/input/ 2> /dev/null\n",
    "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
    "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
    "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
    "\n",
    "try:\n",
    "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "try:\n",
    "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "\n",
    "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
    "    directory, download_url_encoded = data_source_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    filename = urlparse(download_url).path\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = fileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
    "            dl = 0\n",
    "            data = fileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = fileres.read(CHUNK_SIZE)\n",
    "            if filename.endswith('.zip'):\n",
    "              with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "            else:\n",
    "              with tarfile.open(tfile.name) as tarfile:\n",
    "                tarfile.extractall(destination_path)\n",
    "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "\n",
    "print('Data source import complete.')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_dir = \"../input/ucf-crime-dataset/Train\"\n",
    "test_dir = \"../input/ucf-crime-dataset/Test\"\n",
    "\n",
    "SEED = 12\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1\n",
    "LR =  0.00003\n",
    "NUM_CLASSES = 14\n",
    "CLASS_LABELS = ['Abuse','Arrest','Arson','Assault','Burglary','Explosion','Fighting',\"Normal\",'RoadAccidents','Robbery','Shooting','Shoplifting','Stealing','Vandalism']\n",
    "\n",
    "preprocess_fun = tf.keras.applications.densenet.preprocess_input\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.05,\n",
    "                                   rescale = 1./255,\n",
    "                                   preprocessing_function=preprocess_fun\n",
    "                                  )\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  preprocessing_function=preprocess_fun\n",
    "                                 )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                    target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = True ,\n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    seed = SEED\n",
    "                                                   )\n",
    "test_generator = test_datagen.flow_from_directory(directory = test_dir,\n",
    "                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = False ,\n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    seed = SEED\n",
    "                                                  )\n",
    "\n",
    "fig = px.bar(x = CLASS_LABELS,\n",
    "             y = [list(train_generator.classes).count(i) for i in np.unique(train_generator.classes)] ,\n",
    "             color = np.unique(train_generator.classes) ,\n",
    "             color_continuous_scale=\"Emrld\")\n",
    "fig.update_xaxes(title=\"Classes\")\n",
    "fig.update_yaxes(title = \"Number of Images\")\n",
    "fig.update_layout(showlegend = True,\n",
    "    title = {\n",
    "        'text': 'Train Data Distribution ',\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()\n",
    "\n",
    "fig = px.bar(x = CLASS_LABELS,\n",
    "             y = [list(test_generator.classes).count(i) for i in np.unique(test_generator.classes)] ,\n",
    "             color = np.unique(train_generator.classes) ,\n",
    "             color_continuous_scale=\"Emrld\")\n",
    "fig.update_xaxes(title=\"Classes\")\n",
    "fig.update_yaxes(title = \"Number of Images\")\n",
    "fig.update_layout(showlegend = True,\n",
    "    title = {\n",
    "        'text': 'Test Data Distribution ',\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()\n",
    "\n",
    "def feature_extractor(inputs):\n",
    "    feature_extractor = tf.keras.applications.DenseNet121(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights=\"imagenet\")(inputs)\n",
    "\n",
    "    return feature_extractor\n",
    "\n",
    "def classifier(inputs):\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.4) (x)\n",
    "    x = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"classification\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def final_model(inputs):\n",
    "    densenet_feature_extractor = feature_extractor(inputs)\n",
    "    classification_output = classifier(densenet_feature_extractor)\n",
    "\n",
    "    return classification_output\n",
    "\n",
    "def define_compile_model():\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(IMG_HEIGHT ,IMG_WIDTH,3))\n",
    "    classification_output = final_model(inputs)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(LR),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics = [tf.keras.metrics.AUC()])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = define_compile_model()\n",
    "clear_output()\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x = train_generator,validation_data=test_generator,epochs = 1)\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(model,open('model.pkl','wb'))\n",
    "\n",
    "preds = model.predict(test_generator)\n",
    "y_test = test_generator.classes\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (15,8))\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    for (idx, c_label) in enumerate(CLASS_LABELS):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
    "        c_ax.plot(fpr, tpr,lw=2, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "    c_ax.plot(fpr, fpr, 'black',linestyle='dashed', lw=4, label = 'Random Guessing')\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "print('ROC AUC score:', multiclass_roc_auc_score(y_test , preds  , average = \"micro\"))\n",
    "plt.xlabel('FALSE POSITIVE RATE', fontsize=18)\n",
    "plt.ylabel('TRUE POSITIVE RATE', fontsize=16)\n",
    "plt.legend(fontsize = 11.5)\n",
    "plt.show()\n",
    "\n",
    "import cv2\n",
    "\n",
    "def predict_video_anomaly(video_path, model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    predictions = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        frame = preprocess_fun(frame)\n",
    "        frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "        pred = model.predict(frame)\n",
    "        predictions.append(pred)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    average_prediction = np.mean(predictions, axis=0)\n",
    "    threshold = 0.5  # Adjust as needed\n",
    "    is_anomaly = np.any(average_prediction > threshold)\n",
    "\n",
    "    return is_anomaly\n",
    "\n",
    "video_path = \"/content/Vandalism023_x264.mp4\"\n",
    "is_anomaly = predict_video_anomaly(video_path, model)\n",
    "\n",
    "if is_anomaly:\n",
    "    print(\"The video contains an anomaly.\")\n",
    "else:\n",
    "    print(\"The video does not contain any anomaly.\")\n",
    "\n",
    "# Optionally, calculate accuracy score using a separate validation dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
